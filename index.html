<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Roshan Roy</title>

    <meta name="author" content="Roshan Roy">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>游깷</text></svg>">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Roshan Roy
                </p>
                <p>I'm a second-year MS in Computer Vision student at <a href="https://www.cs.cmu.edu/">Carnegie Mellon University</a>, advised by <a href="https://laszlojeni.com/">L치szl칩 Jeni</a>. 
                  My research revolves around foundational models for 2d-to-3d reconstruction in sparse keypoint-centric settings. Earlier, I was an undergrad in CS at <a href="https://www.bits-pilani.ac.in/">BITS Pilani</a>, advised by <a href="https://vcg.seas.harvard.edu/people/hanspeter-pfister">Hanspeter Pfister</a> at <a href="https://seas.harvard.edu/">Harvard University</a>.
                  
                </p>
                <p>
                  I also work at <a href="https://www.lockheedmartin.com/en-us/who-we-are/business-areas/rotary-and-mission-systems.html">Lockheed Martin Research</a>, where I've patented cutting-edge missile trajectory prediction algorithms. 
                  In the past, I've worked at <a href="https://mbrdna.com/">Mercedes-Benz Research</a> on Uncertainty Quantification frameworks for autonomous navigation, and at <a href="https://www.nvidia.com/en-us/clara/">NVIDIA</a> on detection systems for medical diagnostics.
                  
                </p>
                <p style="text-align:center">
                  <a href="mailto:rroshanroy@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/RoshanRoy-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=HFvcbj0AAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/rroshanroy">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/roshan_cropped.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/roshan_cropped.jpeg" class="hoverZoomLink"></a>
              </td>
            </tr>

          <!-- Recent Work Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Recent News</h2>
                  <ul>
                    <li><strong>[Jan/2024]</strong> Continuing as a Research Engineer II at Lockheed Martin!</li>
                    <li><strong>[Dec/2023]</strong> Catch me chat about contested logistics at the <a href="https://www.sae.org/attend/defense-maintenance-and-logistics-exhibition/2023">DoD Maintenance Symposium</a>!</li>
                    <li> <strong>[Sept/2023]</strong> Started M.S. Computer Vision at CMU!</li>
                  </ul>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>    

          <!-- Research Section -->
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Select Research</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

      <!-- <tr bgcolor="#ffffd0"> -->
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <img src='research/find3r/thumbnail.png' width="160">
          </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="">
            <span class="papertitle">Mixed, Not Attended: Why Attention Fails in Unsupervised 3D Lifting</span>
          </a>
          <br>
          Mosam Dabhi,
          <strong>Roshan Roy* </strong>,
          Ananya Bal*,
          George Wei,
          Simon Lucey,
          L치szl칩 Jeni
          <br>
          <strong>Under Review, 2025.</strong>
          <br>
          <a href="">arXiv</a>
          <p>
          Investigating the stability and failure of attention in self-supervised 3D lifting.
          </p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <img src='research/jsd_rl/jsd_thumbnail.png' width="160">
          </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://openreview.net/forum?id=PRBspmgNkY&noteId=cAtQQmmb4n">
            <span class="papertitle">Jensen Shannon Divergence in Safe Multi-Agent RL</span>
          </a>
          <br>
          Rushikesh Zawar*,
          Prabhdeep Sethi*,
          <strong>Roshan Roy* </strong>
          <br>
          <strong>ICLR 2024, Tiny Papers</strong>
          <br>
          <a href="https://openreview.net/pdf?id=PRBspmgNkY">Short Paper</a>
          <p>
          Using Jensen Shannon Divergence to improve both safety and performance in multi-agent reinforcement learning.
          </p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <img src='research/vl4pose/thumbnail.png' width="160">
          </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2210.06028">
            <span class="papertitle">VL4Pose: Active Learning Through
              Out-Of-Distribution Detection For Pose
              Estimation</span>
          </a>
          <br>
          Megh Shukla,
          <strong>Roshan Roy* </strong>,
          Pankaj Singh,
          Shuaib Ahmed,
          Alexandre Alahi
          <br>
          <strong>BMVC 2022</strong>
          <br>
          <a href="https://arxiv.org/pdf/2210.06028">Paper</a>
          <p>
            A first-principles approach to 
            active learning via estimation of heteroscedatic epistemic uncertainty.
          </p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <img src='research/youmvos/thumbnail.png' width="160">
          </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://openaccess.thecvf.com/content/CVPR2022/html/Wei_YouMVOS_An_Actor-Centric_Multi-Shot_Video_Object_Segmentation_Dataset_CVPR_2022_paper.html">
            <span class="papertitle">YouMVOS: An Actor-centric Multi-shot Video Object Segmentation Dataset</span>
          </a>
          <br>
          Donglai Wei*,
          Siddhant Kharbanda*,          
          <strong>Roshan Roy </strong>,
          Hanspeter Pfister et al.
          <br>
          <strong>CVPR 2022</strong>
          <br>
          <a href="https://donglaiw.github.io/proj/youMVOS/">Project Page</a> / 
          <a href="https://donglaiw.github.io/paper/2022_cvpr_youmvos.pdf">Paper</a>
          <p>
          Advancing complex, multi-shot video object segmentation.
          </p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <img src='research/mrscatt/thumbnail.png' width="160">
          </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/html/Chakravarthy_MRSCAtt_A_Spatio-Channel_Attention-Guided_Network_for_Mars_Rover_Image_Classification_CVPRW_2021_paper.html">
            <span class="papertitle">MRSCAtt: A Spatio-Channel Attention-Guided Network for Rover Navigation</span>
          </a>
          <br>
          Anirudh S. Chakravarthy*,
          Praveen Ravirathinam*,          
          <strong>Roshan Roy*</strong>
          <br>
          <strong>CVPR 2021</strong>, AI4Space Workshop
          <br>
          <a href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/papers/Chakravarthy_MRSCAtt_A_Spatio-Channel_Attention-Guided_Network_for_Mars_Rover_Image_Classification_CVPRW_2021_paper.pdf">Paper</a>
          <p>
          A spatio-channel attention-guided network for extraterrestrial rover navigation.
          </p>
        </td>
      </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>           
          
        <!-- Projects Section -->
        </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Projects</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='projects/16825/thumbnail.png' width="160">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle">Cleaning Casually Captured Splatting Scenes with Diffusion Priors</span>
                <br>
                <strong>Roshan Roy</strong>,
                <a href="">Bhuvan Jhamb</a>,
                <a href="">Joel Julin</a>
                <a href="">Jeff Tan</a>,
                <br>
                <a href="https://rroshanroy.github.io/projects/16825/project.pdf">Report</a>
                <p>We fine-tune image-conditioned diffusion models to simultaneously remove ghostly artifacts and infill plausible geometry at novel views.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='projects/16824/thumbnail.png' width="160">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle">Are Masked Autoencoders Actually Scalable Spatio-temporal Learners?</span>
                <br>
                <strong>Roshan Roy</strong>,
                <a href="">Eric Cai</a>
                <a href="">Kyutae Sim</a>
                <a href="">Michaela Tecson</a>
                <br>
                <a href="https://rroshanroy.github.io/projects/16824/project.pdf">Report</a>
                <p>We investigate if masked video pre-training can serve as a universal backbone for both image and video tasks.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='projects/16822/thumbnail.png' width="160">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle">Camera Preconditioning for Neural Radiance Fields in Nerfstudio</span>
                <br>
                <strong>Roshan Roy</strong>,
                <a href="">Sahil Jain</a>,
                <a href="">Bhuvan Jhamb</a>,
                <br>
                <a href="https://rroshanroy.github.io/projects/16822/project.pdf">Report</a>
                <p>We implement a camera preconditioning module for Nerfstudio, which allows for more consistent and stable training of neural radiance fields.</p>
              </td>
            </tr>

          </tbody></table>
          <!-- Footer -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                Website under construction as of March 13 2025. Template credit to <a href="https://jonbarron.info/">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>